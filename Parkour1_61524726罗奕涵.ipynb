{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2917b765",
   "metadata": {},
   "source": [
    "environment setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4479bb8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "from ultralytics import YOLO\n",
    "import os\n",
    "import csv\n",
    "from tqdm import tqdm\n",
    "from IPython.display import HTML, Video\n",
    "import base64\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d451bc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ OpenCV: 4.12.0\n",
      "✓ NumPy: 2.2.6\n",
      "✓ OS: nt\n",
      "✓ CSV: 1.0\n"
     ]
    }
   ],
   "source": [
    "print(f\"✓ OpenCV: {cv2.__version__}\")\n",
    "print(f\"✓ NumPy: {np.__version__}\")\n",
    "print(f\"✓ OS: {os.name}\")\n",
    "print(f\"✓ CSV: {csv.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "292f246b",
   "metadata": {},
   "source": [
    "frame preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "44cb386c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_frame(frame):\n",
    "    \"\"\"\n",
    "    Preprocess frame using CLAHE for better detection\n",
    "    \n",
    "    Args:\n",
    "        frame: Input BGR image\n",
    "    \n",
    "    Returns:\n",
    "        enhanced: Enhanced BGR image\n",
    "    \"\"\"\n",
    "    # Convert to LAB color space (correct approach)\n",
    "    lab = cv2.cvtColor(frame, cv2.COLOR_BGR2LAB)\n",
    "    \n",
    "    # Split channels\n",
    "    l, a, b = cv2.split(lab)\n",
    "    \n",
    "    # Apply CLAHE to L channel\n",
    "    clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8,8))\n",
    "    l_enhanced = clahe.apply(l)\n",
    "    \n",
    "    # Merge channels\n",
    "    enhanced_lab = cv2.merge((l_enhanced, a, b))\n",
    "    \n",
    "    # Convert back to BGR\n",
    "    enhanced = cv2.cvtColor(enhanced_lab, cv2.COLOR_LAB2BGR)\n",
    "    \n",
    "    # Apply slight blur to reduce noise\n",
    "    enhanced = cv2.GaussianBlur(enhanced, (3, 3), 0)\n",
    "    \n",
    "    return enhanced"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d621047f",
   "metadata": {},
   "source": [
    "model configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "21ed81f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=YOLO('yolov8n.pt')\n",
    "\n",
    "TARGET_CLASS = 0  # Person class\n",
    "CONFIDENCE_THRESHOLD = 0.5\n",
    "IOU_THRESHOLD = 0.45\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "99a0b49f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: YOLOv8 Nano\n",
      "Target Class: Person (class_id=0)\n",
      "Confidence Threshold: 0.5\n",
      "IoU Threshold: 0.45\n",
      "Device: CPU\n"
     ]
    }
   ],
   "source": [
    "print(f\"Model: YOLOv8 Nano\")\n",
    "print(f\"Target Class: Person (class_id={TARGET_CLASS})\")\n",
    "print(f\"Confidence Threshold: {CONFIDENCE_THRESHOLD}\")\n",
    "print(f\"IoU Threshold: {IOU_THRESHOLD}\")\n",
    "print(f\"Device: CPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87283913",
   "metadata": {},
   "source": [
    "video configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2aa84dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_VIDEO = r\"C:\\yolovideo\\parkour.mp4\"  \n",
    "OUTPUT_DIR = \"output\"\n",
    "OUTPUT_VIDEO = os.path.join(OUTPUT_DIR, \"parkour_tracked.mp4\")\n",
    "OUTPUT_CSV = os.path.join(OUTPUT_DIR, \"tracking_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a454d9a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output directory created: output\n"
     ]
    }
   ],
   "source": [
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "print(f\"Output directory created: {OUTPUT_DIR}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6d88fff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(INPUT_VIDEO):\n",
    "    print(f\"Warning: Video not found at {INPUT_VIDEO}\")\n",
    "    print(\"Please update the INPUT_VIDEO path to your actual video location\")\n",
    "    # 如果找不到C盘的视频，尝试当前目录\n",
    "    alternate_path = \"0f4398279b513133a7bdfc0f82fe4633.MP4\"\n",
    "    if os.path.exists(alternate_path):\n",
    "        INPUT_VIDEO = alternate_path\n",
    "        print(f\"Using alternate video: {INPUT_VIDEO}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ad269028",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(INPUT_VIDEO)\n",
    "if not cap.isOpened():\n",
    "    raise ValueError(f\"Cannot open video: {INPUT_VIDEO}\")\\\n",
    "\n",
    "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "duration = total_frames / fps if fps > 0 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "02f4b296",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Video: C:\\yolovideo\\parkour.mp4\n",
      "Resolution: 640x360\n",
      "FPS: 14\n",
      "Total Frames: 282\n",
      "Duration: 20.14 seconds\n",
      "Output Video: output\\parkour_tracked.mp4\n",
      "Output CSV: output\\tracking_data.csv\n"
     ]
    }
   ],
   "source": [
    "print(f\"Input Video: {INPUT_VIDEO}\")\n",
    "print(f\"Resolution: {width}x{height}\")\n",
    "print(f\"FPS: {fps}\")\n",
    "print(f\"Total Frames: {total_frames}\")\n",
    "print(f\"Duration: {duration:.2f} seconds\")\n",
    "print(f\"Output Video: {OUTPUT_VIDEO}\")\n",
    "print(f\"Output CSV: {OUTPUT_CSV}\")\n",
    "\n",
    "cap.release()   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee71053c",
   "metadata": {},
   "source": [
    "tracking  system implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f7b3924d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleTracker:\n",
    "    \"\"\"简化的质心追踪器\"\"\"\n",
    "    def __init__(self, max_lost=30, max_dist=100):\n",
    "        self.next_id = 0\n",
    "        self.objects = {}  # {id: {'center': [x,y], 'box': [x1,y1,x2,y2], 'lost': 0}}\n",
    "        self.max_lost = max_lost\n",
    "        self.max_dist = max_dist\n",
    "    \n",
    "    def update(self, boxes):\n",
    "        \"\"\"更新追踪\"\"\"\n",
    "        # 计算新检测的中心点\n",
    "        new_centers = []\n",
    "        for box in boxes:\n",
    "            x1, y1, x2, y2 = box\n",
    "            center = [(x1+x2)/2, (y1+y2)/2]\n",
    "            new_centers.append(center)\n",
    "        \n",
    "        # 如果没有检测到任何对象\n",
    "        if len(boxes) == 0:\n",
    "            # 增加所有对象的丢失计数\n",
    "            for obj_id in list(self.objects.keys()):\n",
    "                self.objects[obj_id]['lost'] += 1\n",
    "                # 删除丢失太久的对象\n",
    "                if self.objects[obj_id]['lost'] > self.max_lost:\n",
    "                    del self.objects[obj_id]\n",
    "            return self.objects\n",
    "        \n",
    "        # 如果没有已追踪对象，全部注册为新对象\n",
    "        if len(self.objects) == 0:\n",
    "            for center, box in zip(new_centers, boxes):\n",
    "                self.objects[self.next_id] = {\n",
    "                    'center': center,\n",
    "                    'box': box,\n",
    "                    'lost': 0\n",
    "                }\n",
    "                self.next_id += 1\n",
    "            return self.objects\n",
    "        \n",
    "        # 匹配现有对象和新检测\n",
    "        matched = set()  # 已匹配的新检测索引\n",
    "        \n",
    "        for obj_id, obj in list(self.objects.items()):\n",
    "            best_match = -1\n",
    "            best_dist = self.max_dist\n",
    "            \n",
    "            # 找最近的新检测\n",
    "            for i, center in enumerate(new_centers):\n",
    "                if i in matched:\n",
    "                    continue\n",
    "                # 计算距离\n",
    "                dist = ((obj['center'][0] - center[0])**2 + \n",
    "                       (obj['center'][1] - center[1])**2)**0.5\n",
    "                if dist < best_dist:\n",
    "                    best_dist = dist\n",
    "                    best_match = i\n",
    "            \n",
    "            # 更新匹配的对象\n",
    "            if best_match >= 0:\n",
    "                self.objects[obj_id] = {\n",
    "                    'center': new_centers[best_match],\n",
    "                    'box': boxes[best_match],\n",
    "                    'lost': 0\n",
    "                }\n",
    "                matched.add(best_match)\n",
    "            else:\n",
    "                # 没找到匹配，增加丢失计数\n",
    "                self.objects[obj_id]['lost'] += 1\n",
    "                if self.objects[obj_id]['lost'] > self.max_lost:\n",
    "                    del self.objects[obj_id]\n",
    "        \n",
    "        # 注册未匹配的新检测\n",
    "        for i, (center, box) in enumerate(zip(new_centers, boxes)):\n",
    "            if i not in matched:\n",
    "                self.objects[self.next_id] = {\n",
    "                    'center': center,\n",
    "                    'box': box,\n",
    "                    'lost': 0\n",
    "                }\n",
    "                self.next_id += 1\n",
    "        \n",
    "        return self.objects"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db725a22",
   "metadata": {},
   "source": [
    "video processing pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c9f581af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_video(input_path, output_path, csv_path):\n",
    "    \"\"\"\n",
    "    Process video with detection and tracking\n",
    "    \"\"\"\n",
    "    # Open video\n",
    "    cap = cv2.VideoCapture(input_path)\n",
    "    if not cap.isOpened():\n",
    "        raise ValueError(f\"Cannot open video: {input_path}\")\n",
    "    \n",
    "    # Get video properties\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    \n",
    "    # Initialize video writer\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
    "    \n",
    "    # Initialize tracker\n",
    "    tracker = SimpleTracker(max_lost=30, max_dist=100)\n",
    "    \n",
    "    # Data storage\n",
    "    tracking_data = []\n",
    "    sample_frames = []\n",
    "    sample_interval = max(1, total_frames // 6)\n",
    "    \n",
    "    print(f\"\\nProcessing {total_frames} frames...\")\n",
    "    \n",
    "    # Process each frame\n",
    "    frame_count = 0\n",
    "    pbar = tqdm(total=total_frames, desc=\"Processing frames\")\n",
    "    \n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        # Preprocess frame\n",
    "        preprocessed = preprocess_frame(frame)\n",
    "        \n",
    "        # Run YOLO detection\n",
    "        results = model(preprocessed,\n",
    "                       classes=[TARGET_CLASS],\n",
    "                       conf=CONFIDENCE_THRESHOLD,\n",
    "                       iou=IOU_THRESHOLD,\n",
    "                       verbose=False)\n",
    "        \n",
    "        # Extract detections\n",
    "        detections = []\n",
    "        if len(results[0].boxes) > 0:\n",
    "            for box in results[0].boxes:\n",
    "                x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()\n",
    "                detections.append([x1, y1, x2, y2])\n",
    "        \n",
    "        # Update tracker\n",
    "        tracked_objects = tracker.update(detections)\n",
    "        \n",
    "        # Draw annotations\n",
    "        annotated_frame = frame.copy()\n",
    "        timestamp = frame_count / fps if fps > 0 else 0\n",
    "        \n",
    "        # Draw timestamp\n",
    "        cv2.putText(annotated_frame, f\"Time: {timestamp:.2f}s\",\n",
    "                   (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "        cv2.putText(annotated_frame, f\"Frame: {frame_count}\",\n",
    "                   (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "        \n",
    "        # Draw tracked objects\n",
    "        for object_id, obj_data in tracked_objects.items():\n",
    "            bbox = obj_data['box']\n",
    "            x1, y1, x2, y2 = [int(v) for v in bbox]\n",
    "            \n",
    "            # Draw bounding box\n",
    "            cv2.rectangle(annotated_frame, (x1, y1), (x2, y2), (0, 255, 255), 2)\n",
    "            \n",
    "            # Draw ID label\n",
    "            label = f\"ID: {object_id}\"\n",
    "            label_size, _ = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.8, 2)\n",
    "            cv2.rectangle(annotated_frame, (x1, y1 - 25),\n",
    "                         (x1 + label_size[0] + 10, y1), (0, 255, 255), -1)\n",
    "            cv2.putText(annotated_frame, label, (x1 + 5, y1 - 7),\n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 0), 2)\n",
    "            \n",
    "            # Save tracking data\n",
    "            tracking_data.append({\n",
    "                'frame': frame_count,\n",
    "                'timestamp': timestamp,\n",
    "                'person_id': object_id,\n",
    "                'x1': x1,\n",
    "                'y1': y1,\n",
    "                'x2': x2,\n",
    "                'y2': y2\n",
    "            })\n",
    "        \n",
    "        # Save sample frames\n",
    "        if frame_count % sample_interval == 0 and len(sample_frames) < 6:\n",
    "            sample_frames.append({\n",
    "                'frame': annotated_frame.copy(),\n",
    "                'timestamp': timestamp,\n",
    "                'frame_num': frame_count\n",
    "            })\n",
    "        \n",
    "        # Write frame\n",
    "        out.write(annotated_frame)\n",
    "        \n",
    "        frame_count += 1\n",
    "        pbar.update(1)\n",
    "    \n",
    "    pbar.close()\n",
    "    \n",
    "    # Release resources\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "    print(f\"Video processing completed!\")\n",
    "    print(f\"Output saved to: {output_path}\")\n",
    "    \n",
    "    return tracking_data, sample_frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5291c380",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing 282 frames...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing frames: 100%|██████████| 282/282 [00:03<00:00, 77.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video processing completed!\n",
      "Output saved to: output\\parkour_tracked.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tracking_data, sample_frames = process_video(INPUT_VIDEO, OUTPUT_VIDEO, OUTPUT_CSV)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad9a16d9",
   "metadata": {},
   "source": [
    "data logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "828d3d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_tracking_data(data, csv_path):\n",
    "    \"\"\"\n",
    "    Save tracking data to CSV file\n",
    "    \"\"\"\n",
    "    if not data:\n",
    "        print(\"No tracking data to save\")\n",
    "        return\n",
    "    \n",
    "    # Write CSV\n",
    "    with open(csv_path, 'w', newline='') as csvfile:\n",
    "        fieldnames = ['frame', 'timestamp', 'person_id', 'x1', 'y1', 'x2', 'y2']\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "        \n",
    "        writer.writeheader()\n",
    "        writer.writerows(data)\n",
    "    \n",
    "    print(f\"\\nTracking data saved to: {csv_path}\")\n",
    "    \n",
    "    # Display statistics\n",
    "    unique_ids = set(row['person_id'] for row in data)\n",
    "    total_detections = len(data)\n",
    "    \n",
    "    print(f\"\\nTracking Statistics:\")\n",
    "    print(f\"  - Total detections: {total_detections}\")\n",
    "    print(f\"  - Number of people tracked: {len(unique_ids)}\")\n",
    "    print(f\"  - Person IDs: {sorted(unique_ids)}\")\n",
    "    \n",
    "    # Per-person statistics\n",
    "    person_frames = {}\n",
    "    for row in data:\n",
    "        pid = row['person_id']\n",
    "        if pid not in person_frames:\n",
    "            person_frames[pid] = []\n",
    "        person_frames[pid].append(row['frame'])\n",
    "    \n",
    "    print(f\"\\nPer-person tracking duration:\")\n",
    "    for pid in sorted(person_frames.keys()):\n",
    "        frames = person_frames[pid]\n",
    "        duration = (max(frames) - min(frames)) / fps if fps > 0 else 0\n",
    "        print(f\"  - Person {pid}: {len(frames)} frames ({duration:.2f}s)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e2bd4026",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tracking data saved to: output\\tracking_data.csv\n",
      "\n",
      "Tracking Statistics:\n",
      "  - Total detections: 904\n",
      "  - Number of people tracked: 17\n",
      "  - Person IDs: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16]\n",
      "\n",
      "Per-person tracking duration:\n",
      "  - Person 0: 282 frames (20.07s)\n",
      "  - Person 1: 126 frames (8.93s)\n",
      "  - Person 2: 69 frames (4.86s)\n",
      "  - Person 3: 31 frames (2.14s)\n",
      "  - Person 4: 37 frames (2.57s)\n",
      "  - Person 5: 31 frames (2.14s)\n",
      "  - Person 6: 33 frames (2.29s)\n",
      "  - Person 7: 31 frames (2.14s)\n",
      "  - Person 8: 31 frames (2.14s)\n",
      "  - Person 9: 31 frames (2.14s)\n",
      "  - Person 10: 31 frames (2.14s)\n",
      "  - Person 11: 60 frames (4.21s)\n",
      "  - Person 12: 31 frames (2.14s)\n",
      "  - Person 13: 54 frames (3.79s)\n",
      "  - Person 14: 15 frames (1.00s)\n",
      "  - Person 15: 10 frames (0.64s)\n",
      "  - Person 16: 1 frames (0.00s)\n"
     ]
    }
   ],
   "source": [
    "save_tracking_data(tracking_data, OUTPUT_CSV)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "434bc821",
   "metadata": {},
   "source": [
    "result visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1863e04",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "def visualize_results(sample_frames):\n",
    "    \"\"\"Safer visualization that prevents kernel crashes\"\"\"\n",
    "    if not sample_frames:\n",
    "        print(\"No sample frames to display\")\n",
    "        return\n",
    "    \n",
    "    try:\n",
    "        # Use Agg backend to avoid GUI issues\n",
    "        import matplotlib\n",
    "        matplotlib.use('Agg')\n",
    "        import matplotlib.pyplot as plt\n",
    "        \n",
    "        # Create figure with error handling\n",
    "        fig = plt.figure(figsize=(15, 10))\n",
    "        \n",
    "        # Display only available frames (max 6)\n",
    "        num_frames = min(len(sample_frames), 6)\n",
    "        \n",
    "        for i in range(num_frames):\n",
    "            plt.subplot(2, 3, i+1)\n",
    "            frame_rgb = cv2.cvtColor(sample_frames[i]['frame'], cv2.COLOR_BGR2RGB)\n",
    "            plt.imshow(frame_rgb)\n",
    "            plt.title(f\"Frame {sample_frames[i]['frame_num']}\")\n",
    "            plt.axis('off')\n",
    "        \n",
    "        plt.suptitle('Parkour Tracking Results')\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        # Save instead of show (prevents GUI issues)\n",
    "        output_path = os.path.join(OUTPUT_DIR, 'tracking_visualization.png')\n",
    "        plt.savefig(output_path, dpi=100, bbox_inches='tight')\n",
    "        plt.close()  # Important: close the figure to free memory\n",
    "        \n",
    "        print(f\"Visualization saved to: {output_path}\")\n",
    "        \n",
    "        # Display the saved image in notebook\n",
    "        from IPython.display import Image, display\n",
    "        display(Image(output_path))\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Visualization error: {e}\")\n",
    "        print(\"Skipping visualization but continuing with the rest of the code\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e279d98e",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_results(sample_frames)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (dl)",
   "language": "python",
   "name": "dl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
